{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30df16d1-5e88-4070-92a7-9e548e8fed78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a205526-cef8-4357-9a95-550ac0ace819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0530c19-889d-4ab9-8ed8-137d59e2fdda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv('https://raw.githubusercontent.com/guebin/MP2023/main/posts/employment.csv')\n",
    "df_train\n",
    "X = pd.get_dummies(df_train[['toeic','gpa']])\n",
    "Y = df_train[['employment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98508bd3-a38d-4346-b062-3de0c92d92a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 784us/step - loss: 0.4801 - accuracy: 0.5020\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 758us/step - loss: 0.4109 - accuracy: 0.4860\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 677us/step - loss: 0.4088 - accuracy: 0.4960\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 654us/step - loss: 0.3409 - accuracy: 0.5060\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 659us/step - loss: 0.3178 - accuracy: 0.5080\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 642us/step - loss: 0.2569 - accuracy: 0.5620\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.3526 - accuracy: 0.5360\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 636us/step - loss: 0.2452 - accuracy: 0.6060\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 644us/step - loss: 0.2451 - accuracy: 0.6400\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 649us/step - loss: 0.2393 - accuracy: 0.6400\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 646us/step - loss: 0.2290 - accuracy: 0.6160\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 647us/step - loss: 0.2045 - accuracy: 0.6900\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 641us/step - loss: 0.2870 - accuracy: 0.5860\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 648us/step - loss: 0.2420 - accuracy: 0.6280\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 650us/step - loss: 0.1949 - accuracy: 0.6980\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 646us/step - loss: 0.2214 - accuracy: 0.6720\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 660us/step - loss: 0.1891 - accuracy: 0.6980\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 644us/step - loss: 0.1848 - accuracy: 0.7160\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 650us/step - loss: 0.1732 - accuracy: 0.7480\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 645us/step - loss: 0.1818 - accuracy: 0.7500\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 639us/step - loss: 0.1649 - accuracy: 0.7720\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 667us/step - loss: 0.2311 - accuracy: 0.6560\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.6980\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 639us/step - loss: 0.1641 - accuracy: 0.7740\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 645us/step - loss: 0.1733 - accuracy: 0.7540\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 635us/step - loss: 0.2121 - accuracy: 0.6840\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 628us/step - loss: 0.1743 - accuracy: 0.7560\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1756 - accuracy: 0.7420\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 630us/step - loss: 0.1543 - accuracy: 0.7780\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 629us/step - loss: 0.1729 - accuracy: 0.7480\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 630us/step - loss: 0.1534 - accuracy: 0.7920\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1463 - accuracy: 0.7980\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1449 - accuracy: 0.8080\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1510 - accuracy: 0.7820\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1570 - accuracy: 0.7720\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1693 - accuracy: 0.7460\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.8180\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 901us/step - loss: 0.1467 - accuracy: 0.8060\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 668us/step - loss: 0.1436 - accuracy: 0.8080\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 643us/step - loss: 0.1456 - accuracy: 0.7880\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1572 - accuracy: 0.7820\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 635us/step - loss: 0.1452 - accuracy: 0.8160\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 639us/step - loss: 0.1531 - accuracy: 0.7780\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 636us/step - loss: 0.1415 - accuracy: 0.7900\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1354 - accuracy: 0.8060\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1475 - accuracy: 0.8040\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1565 - accuracy: 0.7740\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1434 - accuracy: 0.7740\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 638us/step - loss: 0.1508 - accuracy: 0.7780\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1261 - accuracy: 0.8220\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1425 - accuracy: 0.8040\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1384 - accuracy: 0.8060\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1468 - accuracy: 0.7780\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1266 - accuracy: 0.8460\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1369 - accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 645us/step - loss: 0.1579 - accuracy: 0.7660\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1339 - accuracy: 0.8040\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1218 - accuracy: 0.8380\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 637us/step - loss: 0.1296 - accuracy: 0.8140\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 630us/step - loss: 0.1272 - accuracy: 0.8180\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1368 - accuracy: 0.8100\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1740 - accuracy: 0.7380\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1358 - accuracy: 0.7960\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1435 - accuracy: 0.8040\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1355 - accuracy: 0.8120\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1203 - accuracy: 0.8380\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1309 - accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 635us/step - loss: 0.1150 - accuracy: 0.8460\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 635us/step - loss: 0.1319 - accuracy: 0.8220\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1205 - accuracy: 0.8360\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 636us/step - loss: 0.1137 - accuracy: 0.8420\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 648us/step - loss: 0.1192 - accuracy: 0.8360\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 646us/step - loss: 0.1353 - accuracy: 0.7980\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 651us/step - loss: 0.1263 - accuracy: 0.8100\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1095 - accuracy: 0.8540\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1151 - accuracy: 0.8380\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1124 - accuracy: 0.8520\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 636us/step - loss: 0.1135 - accuracy: 0.8540\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 646us/step - loss: 0.1450 - accuracy: 0.7900\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 656us/step - loss: 0.1222 - accuracy: 0.8240\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 644us/step - loss: 0.1174 - accuracy: 0.8320\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 645us/step - loss: 0.1544 - accuracy: 0.7740\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 655us/step - loss: 0.1224 - accuracy: 0.8360\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 684us/step - loss: 0.1495 - accuracy: 0.8020\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 644us/step - loss: 0.1197 - accuracy: 0.8400\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 655us/step - loss: 0.1442 - accuracy: 0.7800\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 644us/step - loss: 0.1242 - accuracy: 0.8240\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 640us/step - loss: 0.1278 - accuracy: 0.8220\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1658 - accuracy: 0.7580\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1258 - accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1195 - accuracy: 0.8340\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1360 - accuracy: 0.8040\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 633us/step - loss: 0.1151 - accuracy: 0.8340\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1277 - accuracy: 0.8100\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 638us/step - loss: 0.1264 - accuracy: 0.8240\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 673us/step - loss: 0.1080 - accuracy: 0.8600\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 632us/step - loss: 0.1020 - accuracy: 0.8560\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 631us/step - loss: 0.1100 - accuracy: 0.8440\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 629us/step - loss: 0.1109 - accuracy: 0.8440\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 634us/step - loss: 0.1040 - accuracy: 0.8580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f65a416cb50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#모델 설정과 딥러닝 구조 결정정\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=2 , activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#딥러닝 실행\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X,Y, epochs=100,batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d8cb008-b1b9-4ba3-b541-e0fec6e440e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 651us/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4927d15e-0060-4925-acf4-3c49fcbd9b16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     employment\n",
       " 0             0\n",
       " 1             0\n",
       " 2             0\n",
       " 3             0\n",
       " 4             1\n",
       " ..          ...\n",
       " 495           1\n",
       " 496           1\n",
       " 497           0\n",
       " 498           0\n",
       " 499           1\n",
       " \n",
       " [500 rows x 1 columns],\n",
       " array([[0.01917117],\n",
       "        [0.27701277],\n",
       "        [0.57248056],\n",
       "        [0.07291598],\n",
       "        [0.9337903 ],\n",
       "        [0.16967887],\n",
       "        [0.04423696],\n",
       "        [0.16271544],\n",
       "        [0.82395774],\n",
       "        [0.03679871],\n",
       "        [0.49401855],\n",
       "        [0.70155656],\n",
       "        [0.74422747],\n",
       "        [0.07437798],\n",
       "        [0.9701731 ],\n",
       "        [0.11984617],\n",
       "        [0.22355464],\n",
       "        [0.9713866 ],\n",
       "        [0.84243065],\n",
       "        [0.34956658],\n",
       "        [0.93221444],\n",
       "        [0.79003614],\n",
       "        [0.8277889 ],\n",
       "        [0.78845423],\n",
       "        [0.67572665],\n",
       "        [0.91666716],\n",
       "        [0.900001  ],\n",
       "        [0.4948617 ],\n",
       "        [0.08570924],\n",
       "        [0.08675035],\n",
       "        [0.45085144],\n",
       "        [0.09457831],\n",
       "        [0.89941543],\n",
       "        [0.89091516],\n",
       "        [0.98111194],\n",
       "        [0.38627425],\n",
       "        [0.500065  ],\n",
       "        [0.07303426],\n",
       "        [0.2076528 ],\n",
       "        [0.39872044],\n",
       "        [0.14696163],\n",
       "        [0.10400353],\n",
       "        [0.849859  ],\n",
       "        [0.6330585 ],\n",
       "        [0.50127107],\n",
       "        [0.12333758],\n",
       "        [0.8664031 ],\n",
       "        [0.27620575],\n",
       "        [0.8914864 ],\n",
       "        [0.25114718],\n",
       "        [0.8564444 ],\n",
       "        [0.86841565],\n",
       "        [0.90393656],\n",
       "        [0.57267356],\n",
       "        [0.07932395],\n",
       "        [0.06170203],\n",
       "        [0.18767741],\n",
       "        [0.24924625],\n",
       "        [0.95436203],\n",
       "        [0.07904566],\n",
       "        [0.03398843],\n",
       "        [0.38441926],\n",
       "        [0.78319013],\n",
       "        [0.8257212 ],\n",
       "        [0.85713553],\n",
       "        [0.3929678 ],\n",
       "        [0.12670748],\n",
       "        [0.95258856],\n",
       "        [0.06235125],\n",
       "        [0.310451  ],\n",
       "        [0.36083743],\n",
       "        [0.32625353],\n",
       "        [0.9480908 ],\n",
       "        [0.66629976],\n",
       "        [0.27613765],\n",
       "        [0.24882582],\n",
       "        [0.5382514 ],\n",
       "        [0.9798404 ],\n",
       "        [0.9588324 ],\n",
       "        [0.9194008 ],\n",
       "        [0.63055253],\n",
       "        [0.5876403 ],\n",
       "        [0.2970832 ],\n",
       "        [0.8484085 ],\n",
       "        [0.89806634],\n",
       "        [0.40804952],\n",
       "        [0.9729422 ],\n",
       "        [0.87672734],\n",
       "        [0.933373  ],\n",
       "        [0.73566663],\n",
       "        [0.98569727],\n",
       "        [0.7418684 ],\n",
       "        [0.90864396],\n",
       "        [0.8763635 ],\n",
       "        [0.7899342 ],\n",
       "        [0.7961238 ],\n",
       "        [0.10964687],\n",
       "        [0.91110736],\n",
       "        [0.05452807],\n",
       "        [0.42326584],\n",
       "        [0.8430349 ],\n",
       "        [0.8250593 ],\n",
       "        [0.57293916],\n",
       "        [0.17664742],\n",
       "        [0.03240925],\n",
       "        [0.40322167],\n",
       "        [0.7187368 ],\n",
       "        [0.40607226],\n",
       "        [0.88016856],\n",
       "        [0.48957664],\n",
       "        [0.98425466],\n",
       "        [0.29335815],\n",
       "        [0.93182445],\n",
       "        [0.09154762],\n",
       "        [0.91493297],\n",
       "        [0.8811433 ],\n",
       "        [0.64865637],\n",
       "        [0.03991823],\n",
       "        [0.94465333],\n",
       "        [0.8167183 ],\n",
       "        [0.01954143],\n",
       "        [0.05376468],\n",
       "        [0.57212585],\n",
       "        [0.05252383],\n",
       "        [0.9681868 ],\n",
       "        [0.96812886],\n",
       "        [0.94278234],\n",
       "        [0.9837329 ],\n",
       "        [0.5691354 ],\n",
       "        [0.88369924],\n",
       "        [0.11227809],\n",
       "        [0.53355527],\n",
       "        [0.87268454],\n",
       "        [0.35719532],\n",
       "        [0.27300215],\n",
       "        [0.67220396],\n",
       "        [0.97631776],\n",
       "        [0.8732753 ],\n",
       "        [0.9843648 ],\n",
       "        [0.9656994 ],\n",
       "        [0.95308733],\n",
       "        [0.6931385 ],\n",
       "        [0.81876254],\n",
       "        [0.96818775],\n",
       "        [0.5238588 ],\n",
       "        [0.8196187 ],\n",
       "        [0.8168527 ],\n",
       "        [0.58253735],\n",
       "        [0.88458246],\n",
       "        [0.83249867],\n",
       "        [0.1201875 ],\n",
       "        [0.8826075 ],\n",
       "        [0.93429315],\n",
       "        [0.77423817],\n",
       "        [0.02924814],\n",
       "        [0.38178807],\n",
       "        [0.3466166 ],\n",
       "        [0.9653925 ],\n",
       "        [0.79927737],\n",
       "        [0.22591524],\n",
       "        [0.07185473],\n",
       "        [0.82701117],\n",
       "        [0.05066053],\n",
       "        [0.23043263],\n",
       "        [0.41072193],\n",
       "        [0.92123693],\n",
       "        [0.90527797],\n",
       "        [0.76721424],\n",
       "        [0.6522743 ],\n",
       "        [0.34334943],\n",
       "        [0.63762605],\n",
       "        [0.19859885],\n",
       "        [0.97158444],\n",
       "        [0.8913412 ],\n",
       "        [0.08545599],\n",
       "        [0.95702195],\n",
       "        [0.9546011 ],\n",
       "        [0.7769809 ],\n",
       "        [0.6955107 ],\n",
       "        [0.959477  ],\n",
       "        [0.13949394],\n",
       "        [0.88012   ],\n",
       "        [0.9681104 ],\n",
       "        [0.16866204],\n",
       "        [0.81970745],\n",
       "        [0.06679367],\n",
       "        [0.50428295],\n",
       "        [0.97363365],\n",
       "        [0.13436674],\n",
       "        [0.73526573],\n",
       "        [0.3802947 ],\n",
       "        [0.3797849 ],\n",
       "        [0.92563415],\n",
       "        [0.93689096],\n",
       "        [0.17957757],\n",
       "        [0.14559893],\n",
       "        [0.8678163 ],\n",
       "        [0.88208693],\n",
       "        [0.97858894],\n",
       "        [0.6803263 ],\n",
       "        [0.88837254],\n",
       "        [0.6473557 ],\n",
       "        [0.713776  ],\n",
       "        [0.98046607],\n",
       "        [0.40170547],\n",
       "        [0.9541457 ],\n",
       "        [0.33725163],\n",
       "        [0.07588536],\n",
       "        [0.19491214],\n",
       "        [0.61104286],\n",
       "        [0.14010936],\n",
       "        [0.91630405],\n",
       "        [0.03834961],\n",
       "        [0.72811943],\n",
       "        [0.34053385],\n",
       "        [0.62020403],\n",
       "        [0.07496268],\n",
       "        [0.3621057 ],\n",
       "        [0.77371186],\n",
       "        [0.79291373],\n",
       "        [0.24495268],\n",
       "        [0.14030856],\n",
       "        [0.98848253],\n",
       "        [0.21629004],\n",
       "        [0.77385217],\n",
       "        [0.4226013 ],\n",
       "        [0.5461467 ],\n",
       "        [0.06345365],\n",
       "        [0.9591146 ],\n",
       "        [0.9653101 ],\n",
       "        [0.9109111 ],\n",
       "        [0.59520805],\n",
       "        [0.12937342],\n",
       "        [0.94690955],\n",
       "        [0.31774738],\n",
       "        [0.07824167],\n",
       "        [0.4035803 ],\n",
       "        [0.970306  ],\n",
       "        [0.86459106],\n",
       "        [0.83906114],\n",
       "        [0.8583879 ],\n",
       "        [0.45989472],\n",
       "        [0.9608893 ],\n",
       "        [0.6475749 ],\n",
       "        [0.9643738 ],\n",
       "        [0.5300669 ],\n",
       "        [0.40387452],\n",
       "        [0.03868933],\n",
       "        [0.4975298 ],\n",
       "        [0.4583777 ],\n",
       "        [0.05485775],\n",
       "        [0.8855906 ],\n",
       "        [0.29030403],\n",
       "        [0.92123866],\n",
       "        [0.41690975],\n",
       "        [0.97260654],\n",
       "        [0.98183936],\n",
       "        [0.05801743],\n",
       "        [0.9789199 ],\n",
       "        [0.94818807],\n",
       "        [0.3699752 ],\n",
       "        [0.3638382 ],\n",
       "        [0.5479293 ],\n",
       "        [0.47763076],\n",
       "        [0.51313263],\n",
       "        [0.49031878],\n",
       "        [0.95143396],\n",
       "        [0.8830845 ],\n",
       "        [0.04611275],\n",
       "        [0.8867892 ],\n",
       "        [0.76889664],\n",
       "        [0.85455334],\n",
       "        [0.18544999],\n",
       "        [0.4523961 ],\n",
       "        [0.6139288 ],\n",
       "        [0.8853227 ],\n",
       "        [0.685312  ],\n",
       "        [0.01474617],\n",
       "        [0.7034919 ],\n",
       "        [0.79860747],\n",
       "        [0.57097834],\n",
       "        [0.72747326],\n",
       "        [0.08300006],\n",
       "        [0.9866009 ],\n",
       "        [0.9491896 ],\n",
       "        [0.4675123 ],\n",
       "        [0.49861518],\n",
       "        [0.8898536 ],\n",
       "        [0.67578405],\n",
       "        [0.8755042 ],\n",
       "        [0.28693882],\n",
       "        [0.7925204 ],\n",
       "        [0.32779872],\n",
       "        [0.99298096],\n",
       "        [0.15786973],\n",
       "        [0.05273386],\n",
       "        [0.07585184],\n",
       "        [0.84367484],\n",
       "        [0.11621627],\n",
       "        [0.3452456 ],\n",
       "        [0.08934698],\n",
       "        [0.4832032 ],\n",
       "        [0.5860667 ],\n",
       "        [0.6686725 ],\n",
       "        [0.05702977],\n",
       "        [0.21380268],\n",
       "        [0.8648583 ],\n",
       "        [0.7823888 ],\n",
       "        [0.24898165],\n",
       "        [0.28666323],\n",
       "        [0.20016862],\n",
       "        [0.2168708 ],\n",
       "        [0.21898386],\n",
       "        [0.4306856 ],\n",
       "        [0.82605165],\n",
       "        [0.36329412],\n",
       "        [0.94152397],\n",
       "        [0.97779167],\n",
       "        [0.7131194 ],\n",
       "        [0.81928974],\n",
       "        [0.03559082],\n",
       "        [0.22447224],\n",
       "        [0.63786954],\n",
       "        [0.95887583],\n",
       "        [0.22680953],\n",
       "        [0.03871967],\n",
       "        [0.22801438],\n",
       "        [0.9555246 ],\n",
       "        [0.99244696],\n",
       "        [0.42094892],\n",
       "        [0.33412814],\n",
       "        [0.97125894],\n",
       "        [0.84219325],\n",
       "        [0.9215936 ],\n",
       "        [0.11309428],\n",
       "        [0.9716536 ],\n",
       "        [0.32081524],\n",
       "        [0.6802617 ],\n",
       "        [0.33729896],\n",
       "        [0.02772723],\n",
       "        [0.8084843 ],\n",
       "        [0.6887507 ],\n",
       "        [0.841458  ],\n",
       "        [0.9155224 ],\n",
       "        [0.09881844],\n",
       "        [0.73725986],\n",
       "        [0.30792457],\n",
       "        [0.5606182 ],\n",
       "        [0.05556777],\n",
       "        [0.8924346 ],\n",
       "        [0.8027948 ],\n",
       "        [0.6102546 ],\n",
       "        [0.02506168],\n",
       "        [0.9593257 ],\n",
       "        [0.32803148],\n",
       "        [0.05519449],\n",
       "        [0.1393818 ],\n",
       "        [0.85458094],\n",
       "        [0.6028396 ],\n",
       "        [0.10856601],\n",
       "        [0.8255928 ],\n",
       "        [0.13584475],\n",
       "        [0.50551504],\n",
       "        [0.96753633],\n",
       "        [0.9437374 ],\n",
       "        [0.8593406 ],\n",
       "        [0.282129  ],\n",
       "        [0.93644136],\n",
       "        [0.60541344],\n",
       "        [0.908679  ],\n",
       "        [0.76774406],\n",
       "        [0.89691186],\n",
       "        [0.2703746 ],\n",
       "        [0.64322895],\n",
       "        [0.29612315],\n",
       "        [0.04659881],\n",
       "        [0.20838122],\n",
       "        [0.49536982],\n",
       "        [0.9574271 ],\n",
       "        [0.9164298 ],\n",
       "        [0.6172774 ],\n",
       "        [0.2583753 ],\n",
       "        [0.51643944],\n",
       "        [0.4519163 ],\n",
       "        [0.75248504],\n",
       "        [0.94678587],\n",
       "        [0.18314745],\n",
       "        [0.02212726],\n",
       "        [0.05176777],\n",
       "        [0.97237957],\n",
       "        [0.5470983 ],\n",
       "        [0.44097656],\n",
       "        [0.86453414],\n",
       "        [0.29728734],\n",
       "        [0.92869407],\n",
       "        [0.73852324],\n",
       "        [0.22985455],\n",
       "        [0.9173276 ],\n",
       "        [0.64710844],\n",
       "        [0.421796  ],\n",
       "        [0.4742776 ],\n",
       "        [0.5329712 ],\n",
       "        [0.6139735 ],\n",
       "        [0.14020257],\n",
       "        [0.8466091 ],\n",
       "        [0.10136232],\n",
       "        [0.9823159 ],\n",
       "        [0.78644043],\n",
       "        [0.24029979],\n",
       "        [0.44837937],\n",
       "        [0.95112103],\n",
       "        [0.98899335],\n",
       "        [0.72358245],\n",
       "        [0.9876894 ],\n",
       "        [0.13090147],\n",
       "        [0.80479366],\n",
       "        [0.18592311],\n",
       "        [0.10133642],\n",
       "        [0.18840505],\n",
       "        [0.05062044],\n",
       "        [0.9519586 ],\n",
       "        [0.8140401 ],\n",
       "        [0.04401746],\n",
       "        [0.26882783],\n",
       "        [0.95578164],\n",
       "        [0.30525184],\n",
       "        [0.06306392],\n",
       "        [0.78950936],\n",
       "        [0.0482501 ],\n",
       "        [0.48453936],\n",
       "        [0.48090762],\n",
       "        [0.66874796],\n",
       "        [0.9488091 ],\n",
       "        [0.86852896],\n",
       "        [0.4179146 ],\n",
       "        [0.9688493 ],\n",
       "        [0.02599564],\n",
       "        [0.98675174],\n",
       "        [0.41479954],\n",
       "        [0.5969038 ],\n",
       "        [0.74173814],\n",
       "        [0.91931564],\n",
       "        [0.01778276],\n",
       "        [0.9395381 ],\n",
       "        [0.9695743 ],\n",
       "        [0.7976663 ],\n",
       "        [0.9694414 ],\n",
       "        [0.9728497 ],\n",
       "        [0.5978612 ],\n",
       "        [0.88861656],\n",
       "        [0.6589707 ],\n",
       "        [0.6629037 ],\n",
       "        [0.24528511],\n",
       "        [0.5953964 ],\n",
       "        [0.9042165 ],\n",
       "        [0.9857699 ],\n",
       "        [0.30555132],\n",
       "        [0.94010955],\n",
       "        [0.18784209],\n",
       "        [0.2734823 ],\n",
       "        [0.50732434],\n",
       "        [0.936694  ],\n",
       "        [0.41610953],\n",
       "        [0.7398132 ],\n",
       "        [0.57886773],\n",
       "        [0.8904059 ],\n",
       "        [0.76505774],\n",
       "        [0.27815723],\n",
       "        [0.938038  ],\n",
       "        [0.16718833],\n",
       "        [0.85088605],\n",
       "        [0.20372394],\n",
       "        [0.8189768 ],\n",
       "        [0.12603728],\n",
       "        [0.62040645],\n",
       "        [0.47599888],\n",
       "        [0.41412124],\n",
       "        [0.96225524],\n",
       "        [0.32949308],\n",
       "        [0.77854615],\n",
       "        [0.50865686],\n",
       "        [0.98446643],\n",
       "        [0.6660308 ],\n",
       "        [0.30000117],\n",
       "        [0.31887043],\n",
       "        [0.34211856],\n",
       "        [0.66088057],\n",
       "        [0.98051924],\n",
       "        [0.38630512],\n",
       "        [0.31678852],\n",
       "        [0.22271015],\n",
       "        [0.3595858 ],\n",
       "        [0.04029208],\n",
       "        [0.29222274],\n",
       "        [0.7604949 ],\n",
       "        [0.9275784 ],\n",
       "        [0.56702435],\n",
       "        [0.02502951],\n",
       "        [0.12665989],\n",
       "        [0.8747921 ]], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ae867-77d3-4e44-8c11-3a00fb4c528d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **위의 딥러닝이 무슨 의미인가요?**\n",
    "`-` 뉴런의 개수와 비활성화함수로 그저 그냥 전미분 함수로 backpropaganda 랑 propaganda 실시 (역전파와 순전파) 로 나오는 그냥 값일 뿐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e88f26-3e79-478c-aead-ddb330860528",
   "metadata": {
    "tags": []
   },
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71acd3-70fe-45f8-bae7-a3ea52dfebcc",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178478e-1793-4998-819d-b60775125ee7",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b37fb-5697-41a4-a53d-763231c7e890",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d4e78-aabf-41c3-b8f9-a60746c20729",
   "metadata": {
    "tags": []
   },
   "source": [
    "### batch_size=10 에 대해서 설명해줘\n",
    "`-` batch_size :  모델 학습 과정에서 한 번에 처리되는 데이터 샘플의 수를 의미합니다\n",
    "\n",
    "- 한 번의 반복(iteration)에서 10개의 샘플 처리 : 랜덤샘플인가요? 통상적으로 순차적인 데이터 \n",
    "#### batch_size = 데이터개수 : 전체값 예측 , batch_size * 데이터 개수 = 전체 데이터개수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa87c61-2714-4793-9a3a-52fa3c75c16b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "`-` batch 를 쓰는 이유 : \n",
    " - batch 가 작으면 모든 것들로 적합하는게 아니라 일정부분만 사용하여 과적합을 피하는 방법이다.\n",
    " - 배치사이즈가 클수록 많은 데이터를 저장해두어야 하므로 용량 커야한다.\n",
    " - 배치사이즈가 작으면 학습은 촘촘하게 되어 시간이 오래 걸린다.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560bc53-e18a-4645-8ac6-d494c017ca92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e508358-8fea-4b8e-b113-d875142c4b6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `-` 최소제곱법\n",
    "- 회귀분석에서 쓰는 가장 MSE 가 적게 만드는 식\n",
    "  - (BLUE 를 만족한다.) 수리통계학과 회귀분석을 이수하였다면 이유를 안다.\n",
    "  - 수리통계학에서 MSE = VAR(T(X)) + 잔차(bias)(=0) 이 최소가 된다. # 여기서 T(X) 는 g(seta) 의 추정량이다.\n",
    "  - 회귀분석에선 미분공식으로 모든 절편의 최소값을 찾는다.) \n",
    "  \n",
    "<br>\n",
    "- 최소제곱법의 계산 : 미분{전미분,편미분(로) 등}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d45a6-754c-4fb4-b0e7-ad584c34c7f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c7617-2968-4e06-a2f7-974dd3648a65",
   "metadata": {},
   "source": [
    ">\n",
    ">\n",
    ">\n",
    ">\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06183dd0-4343-432c-804b-ffe0d5a71887",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 선형회귀\n",
    "\n",
    "- 회귀분석에서 기울기와 절편 등 중회귀모형에서 직접적으로 구하는 방법을 구한다. \n",
    "  1. 식을 구하는 방식을 간단히 단순선형모형에서 식으로 구하기\n",
    "  2. 식을 행렬의 표현을 이용하여 중회귀모형에서 직접 쉽게 구하기.(행렬은 증명을 쉽게 해준다는 장점이 존재)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566cad6-2b35-4100-baa1-79c164dc8943",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfb602-8089-466e-b034-92f2b46624cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 최소제곱법으로 그은 선에 대한 평가가 필요하다.\n",
    "- 최소제곱법은 기울기와 절편이 최소이지만 이 모형이 제대로 우리의 데이터를 표현할 수 없다.\n",
    "  - 그 이유는 우리의 데이터가 전체의 데이터가 아니라 표본이기 때문이다. 그리고 오차가 존재하기 때문이다. 등 더 많은 문제가 있다.\n",
    "`-` 선에대한 평가의 지표를 만들자\n",
    "- 평균제곱오차 MSE 이것이 그의 지표로써 이용된다.\n",
    "- MSE = $ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $ 인데 단순회귀모형에서는 $ n  -> n-2$ , 원점을 지나는 단순회귀모형은$ n  -> n-1 $이런식으로 자유도에 따라서 식이 바뀐다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b65667-2d53-4eb7-a5c2-f8885b215ac2",
   "metadata": {
    "tags": []
   },
   "source": [
    "######  `-` 평가방법은 수리통계학에서의 작은 MSE 찾는 방법과 회귀분석에서의 MSE 계산으로 각종 지표로 유용한 직선인지 평가할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c528a51a-117b-4ccb-b320-62711a6d6f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hf)",
   "language": "python",
   "name": "hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
